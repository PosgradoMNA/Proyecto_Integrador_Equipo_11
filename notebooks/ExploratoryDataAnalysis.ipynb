{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee029178442098a8",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3aac80a0e5620",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "id": "c2daed3cd0ddfea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.431856Z",
     "start_time": "2025-01-26T17:15:04.281702Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pywt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.colors\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "21efb37b5b11dea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.435915Z",
     "start_time": "2025-01-26T17:15:04.432864Z"
    }
   },
   "source": [
    "sns.set(style=\"whitegrid\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "b7376a9619a235e",
   "metadata": {},
   "source": [
    "### Descripción de librerías\n",
    "\n",
    "- **`pandas` (`import pandas as pd`)**: Una librería poderosa para la manipulación y análisis de datos tabulares. Proporciona estructuras como DataFrames y Series, útiles para gestionar datos estructurados de manera eficiente.\n",
    "\n",
    "- **`numpy` (`import numpy as np`)**: Una librería fundamental para el cálculo numérico en Python. Ofrece soporte para matrices y operaciones matemáticas de alto rendimiento.\n",
    "\n",
    "- **`matplotlib.pyplot` (`import matplotlib.pyplot as plt`)**: Un módulo de Matplotlib que permite crear visualizaciones gráficas 2D, como gráficos de líneas, barras, dispersión, entre otros.\n",
    "\n",
    "- **`seaborn` (`import seaborn as sns`)**: Una librería de visualización de datos basada en Matplotlib, que facilita la creación de gráficos estadísticos más atractivos y con estilo.\n",
    "\n",
    "- **`pywt` (`import pywt`)**: Una librería para realizar transformadas wavelet, ampliamente utilizada en el análisis de señales y datos en aplicaciones como procesamiento de imágenes y series temporales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9bf487bc05fa7e",
   "metadata": {},
   "source": [
    "## Carga del Conjunto de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26aafb",
   "metadata": {},
   "source": [
    "**Acerca del set de datos:**\n",
    "\n",
    "Los datos para usar son el conjunto de datos Emothaw desarrollado por (Likforman-Sulem et al., 2017), es un set de datos explícitamente diseñado al estudio de emociones usando análisis y patrones en la escritura.\n",
    "\n",
    "Incluye muestras escritas a mano recopiladas de participantes en diferentes estados emocionales.\n",
    "\n",
    "Estos estados emocionales a menudo se inducen mediante métodos psicológicos validados, como videos o estímulos diseñados para provocar emociones (por ejemplo, felicidad, tristeza, ira, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58997bb3",
   "metadata": {},
   "source": [
    "### **Carga de conjunto de datos**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42725e5c",
   "metadata": {},
   "source": [
    "Los datos se encuentran en formato .csv, estos datos fueron conglomerados anteriormente junto con sus propias etiquetas y guardados en un documento. parquet, el cual usamos para cargar la información de manera mas sencilla.\n",
    "\n",
    "El proceso de conglomerado de datos raw a un .parquet sucede en el notebook [notebooks/DataPreparation.ipynb](https://github.com/PosgradoMNA/Proyecto_Integrador_Equipo_11/blob/main/notebooks/DataPreparation.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cdf4e81a2db9a9a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.572861Z",
     "start_time": "2025-01-26T17:15:04.436919Z"
    }
   },
   "source": [
    "file_path = '../data/raw_binary/labeled_data_timeseries.parquet'\n",
    "df = pd.read_parquet(file_path)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "3f05682c0f2c58cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.593193Z",
     "start_time": "2025-01-26T17:15:04.572861Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         homework  pen_status  \\\n",
       "Subject                         \n",
       "1               1           0   \n",
       "1               1           1   \n",
       "1               2           0   \n",
       "1               2           1   \n",
       "1               3           0   \n",
       "\n",
       "                                                         x  \\\n",
       "Subject                                                      \n",
       "1        [48331, 48318, 48305, 48305, 48305, 48305, 483...   \n",
       "1        [47944, 47949, 47949, 47950, 47950, 47950, 479...   \n",
       "1        [41647, 41714, 41787, 41896, 41896, 41616, 416...   \n",
       "1        [45074, 45128, 45144, 45158, 45164, 45169, 451...   \n",
       "1        [33431, 33563, 33626, 33685, 33747, 33812, 338...   \n",
       "\n",
       "                                                         y  \\\n",
       "Subject                                                      \n",
       "1        [31876, 31963, 32053, 32159, 32159, 32159, 321...   \n",
       "1        [33492, 33506, 33512, 33515, 33519, 33524, 335...   \n",
       "1        [14655, 14657, 14675, 14677, 14677, 15475, 154...   \n",
       "1        [14676, 14676, 14679, 14689, 14696, 14701, 147...   \n",
       "1        [35956, 35956, 35959, 35976, 35991, 36002, 360...   \n",
       "\n",
       "                                                 timestamp  \\\n",
       "Subject                                                      \n",
       "1        [672620, 672628, 672635, 672643, 672650, 67282...   \n",
       "1        [671854, 671861, 671869, 671876, 671884, 67189...   \n",
       "1        [692915, 692922, 692930, 692937, 692945, 69356...   \n",
       "1        [692434, 692441, 692449, 692456, 692464, 69247...   \n",
       "1        [724897, 724905, 724912, 724920, 724927, 72493...   \n",
       "\n",
       "                                                   azimuth  \\\n",
       "Subject                                                      \n",
       "1        [1830, 1830, 1830, 1830, 1830, 1830, 1830, 234...   \n",
       "1        [1800, 1800, 1800, 1800, 1800, 1810, 1810, 181...   \n",
       "1        [1830, 1830, 1830, 1840, 1840, 2530, 2530, 253...   \n",
       "1        [1930, 1940, 1940, 1940, 1940, 1940, 1940, 194...   \n",
       "1        [1760, 1760, 1760, 1760, 1760, 1760, 1770, 177...   \n",
       "\n",
       "                                                  altitude  \\\n",
       "Subject                                                      \n",
       "1        [530, 530, 530, 530, 530, 530, 530, 350, 360, ...   \n",
       "1        [490, 500, 500, 500, 500, 500, 500, 500, 500, ...   \n",
       "1        [530, 530, 530, 530, 530, 450, 450, 450, 460, ...   \n",
       "1        [510, 510, 510, 510, 510, 510, 510, 510, 510, ...   \n",
       "1        [620, 610, 610, 610, 610, 610, 600, 600, 600, ...   \n",
       "\n",
       "                                                  pressure  depression  \\\n",
       "Subject                                                                  \n",
       "1        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           2   \n",
       "1        [67, 148, 193, 228, 270, 306, 341, 365, 381, 3...           2   \n",
       "1        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           2   \n",
       "1        [50, 207, 282, 304, 377, 418, 426, 438, 447, 4...           2   \n",
       "1        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           2   \n",
       "\n",
       "         anxiety  stress  \n",
       "Subject                   \n",
       "1              8      13  \n",
       "1              8      13  \n",
       "1              8      13  \n",
       "1              8      13  \n",
       "1              8      13  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homework</th>\n",
       "      <th>pen_status</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>altitude</th>\n",
       "      <th>pressure</th>\n",
       "      <th>depression</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>stress</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[48331, 48318, 48305, 48305, 48305, 48305, 483...</td>\n",
       "      <td>[31876, 31963, 32053, 32159, 32159, 32159, 321...</td>\n",
       "      <td>[672620, 672628, 672635, 672643, 672650, 67282...</td>\n",
       "      <td>[1830, 1830, 1830, 1830, 1830, 1830, 1830, 234...</td>\n",
       "      <td>[530, 530, 530, 530, 530, 530, 530, 350, 360, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[47944, 47949, 47949, 47950, 47950, 47950, 479...</td>\n",
       "      <td>[33492, 33506, 33512, 33515, 33519, 33524, 335...</td>\n",
       "      <td>[671854, 671861, 671869, 671876, 671884, 67189...</td>\n",
       "      <td>[1800, 1800, 1800, 1800, 1800, 1810, 1810, 181...</td>\n",
       "      <td>[490, 500, 500, 500, 500, 500, 500, 500, 500, ...</td>\n",
       "      <td>[67, 148, 193, 228, 270, 306, 341, 365, 381, 3...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[41647, 41714, 41787, 41896, 41896, 41616, 416...</td>\n",
       "      <td>[14655, 14657, 14675, 14677, 14677, 15475, 154...</td>\n",
       "      <td>[692915, 692922, 692930, 692937, 692945, 69356...</td>\n",
       "      <td>[1830, 1830, 1830, 1840, 1840, 2530, 2530, 253...</td>\n",
       "      <td>[530, 530, 530, 530, 530, 450, 450, 450, 460, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[45074, 45128, 45144, 45158, 45164, 45169, 451...</td>\n",
       "      <td>[14676, 14676, 14679, 14689, 14696, 14701, 147...</td>\n",
       "      <td>[692434, 692441, 692449, 692456, 692464, 69247...</td>\n",
       "      <td>[1930, 1940, 1940, 1940, 1940, 1940, 1940, 194...</td>\n",
       "      <td>[510, 510, 510, 510, 510, 510, 510, 510, 510, ...</td>\n",
       "      <td>[50, 207, 282, 304, 377, 418, 426, 438, 447, 4...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[33431, 33563, 33626, 33685, 33747, 33812, 338...</td>\n",
       "      <td>[35956, 35956, 35959, 35976, 35991, 36002, 360...</td>\n",
       "      <td>[724897, 724905, 724912, 724920, 724927, 72493...</td>\n",
       "      <td>[1760, 1760, 1760, 1760, 1760, 1760, 1770, 177...</td>\n",
       "      <td>[620, 610, 610, 610, 610, 610, 600, 600, 600, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "dcb93d48",
   "metadata": {},
   "source": [
    "Como se puede observar, el dataframe continene las siguientes columnas:\n",
    "\n",
    "*   **Subject** el cual identifica al usuario al que se le hicieron las pruebas.\n",
    "\n",
    "*   **Homework** representa el tipo de dibujo realizado por el usuario. Se tienen 8 tipos de tareas: \n",
    "    \n",
    "    0. Clasificado erróneamente\n",
    "    1. Pentágonos\n",
    "    2. Casa\n",
    "    3. Palabras copiadas a mano\n",
    "    4. Círculos concéntricos dibujados con mano izquierda\n",
    "    5. Círculos concéntricos dibujados con mano derecha\n",
    "    6. Reloj\n",
    "    7. Texto copiado en cursivas\n",
    "\n",
    "*   **pen_status** este nos muestra si la pluma se encuentra arriba (0) o abajo (1).\n",
    "\n",
    "*   **X y Y** son series de tiempo que representan las coordenadas de los trazos en x y y.\n",
    "\n",
    "*   **Azimuth**  son series de tiempo que representan el ángulo entre la orientación del lápiz y una dirección de referencia en el plano de la superficie de la tableta.\n",
    "\n",
    "*   **Altitude** es una serie de tiempo que contiene ángulo entre el lápiz y la superficie de la tableta.\n",
    "\n",
    "*   **Pressure** Presión al escribir en la pluma.\n",
    "\n",
    "*   Nuestras etiquetas serian los valores booleanos designados a las emociones como **depresión, ansiedad y estrés**. De acuerdo con el trabajo desarrollado por (TODO: agregar referencia paper nolazco) se consideraron las etiquetas de acuerdo con lo siguiente:\n",
    "\n",
    "Label | Depression | Anxiety | Stress\n",
    "---:|:---:| --- | ---\n",
    "**Normal (0)** | 0-9 | 0-7 | 0-14\n",
    "**Above Normal (1)** | 10-28+ | 8-20+ | 15-34+\n",
    "\n",
    "En este notebook ya se cuentan con las etiquetas en forma booleana, para ver los valores raw se puede consultar el notebook [notebooks/DataPreparation.ipynb](https://github.com/PosgradoMNA/Proyecto_Integrador_Equipo_11/blob/main/notebooks/DataPreparation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e826eba7e8d154b3",
   "metadata": {},
   "source": [
    "## Estructura de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0b78981a74f4a",
   "metadata": {},
   "source": [
    "### Forma del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "id": "64cbaec75cb062ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.596545Z",
     "start_time": "2025-01-26T17:15:04.594199Z"
    }
   },
   "source": [
    "print(\"Forma del conjunto de datos:\", df.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del conjunto de datos: (1588, 11)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "c5f8bb8c",
   "metadata": {},
   "source": [
    "Podemos observar que nuestros datos actuales tienen la dimensión de (1588, 11), en otras palabras: 1588 ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f7049cd9d2a7",
   "metadata": {},
   "source": [
    "### Tipos de datos y conteo de valores no nulos"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b45b8d004ab689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.605027Z",
     "start_time": "2025-01-26T17:15:04.597552Z"
    }
   },
   "source": [
    "print(\"\\nTipos de datos y conteo de valores no nulos:\")\n",
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos y conteo de valores no nulos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1588 entries, 1 to 129\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   homework    1588 non-null   int64 \n",
      " 1   pen_status  1588 non-null   int64 \n",
      " 2   x           1588 non-null   object\n",
      " 3   y           1588 non-null   object\n",
      " 4   timestamp   1588 non-null   object\n",
      " 5   azimuth     1588 non-null   object\n",
      " 6   altitude    1588 non-null   object\n",
      " 7   pressure    1588 non-null   object\n",
      " 8   depression  1588 non-null   int64 \n",
      " 9   anxiety     1588 non-null   int64 \n",
      " 10  stress      1588 non-null   int64 \n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 148.9+ KB\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "69172e00",
   "metadata": {},
   "source": [
    "En este caso el tipo de dato no indica si la información es categórica o numérica.\n",
    "\n",
    "Variables categóricas (5):\n",
    "- homework\n",
    "- pen_status\n",
    "- depression (label)\n",
    "- anxiety (label)\n",
    "- stress (label)\n",
    "\n",
    "Variables numéricas (5):\n",
    "- x\n",
    "- y\n",
    "- azimuth\n",
    "- altitude\n",
    "- pressure\n",
    "\n",
    "En este caso las variables numéricas ya se encuentran en formato de series de tiempo no como valores individuales.\n",
    "\n",
    "Se considera anular la variable de timestamp dado que las señales ya están ordenadas de manera cronológica en el tiempo y no aporta información adicional para los métodos de clasificación que serán utilizados.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b3a8cad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.608016Z",
     "start_time": "2025-01-26T17:15:04.605027Z"
    }
   },
   "source": [
    "categorical_columns = ['homework', 'pen_status', 'depression', 'anxiety', 'stress']\n",
    "numerical_columns = ['x', 'y', 'azimuth', 'altitude', 'pressure']"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "8b796414",
   "metadata": {},
   "source": [
    "Podemos adicionalmente determinar el tipo de las variables en las series de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8d829d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.611950Z",
     "start_time": "2025-01-26T17:15:04.609021Z"
    }
   },
   "source": [
    "for numerical_col in numerical_columns:\n",
    "    print(f\"Tipo de datos para {numerical_col}: {type(df[numerical_col].iloc[0][0])}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de datos para x: <class 'numpy.int64'>\n",
      "Tipo de datos para y: <class 'numpy.int64'>\n",
      "Tipo de datos para azimuth: <class 'numpy.int64'>\n",
      "Tipo de datos para altitude: <class 'numpy.int64'>\n",
      "Tipo de datos para pressure: <class 'numpy.int64'>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "17ac88a0b5283708",
   "metadata": {},
   "source": [
    "Podemos observar que todos los datos de serie de tiempo son enteros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d58addc73b9a65",
   "metadata": {},
   "source": [
    "### Resumen estadístico para columnas numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b883a",
   "metadata": {},
   "source": [
    "Para el análisis estadístico descriptivo de las variables numéricas se utilizará el dataframe que contiene un sample por fila. "
   ]
  },
  {
   "cell_type": "code",
   "id": "572e4f9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.678957Z",
     "start_time": "2025-01-26T17:15:04.612956Z"
    }
   },
   "source": [
    "file_path = '../data/raw_binary/labeled_data.parquet'\n",
    "df_raw = pd.read_parquet(file_path)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e2e3d717b1d98d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.974623Z",
     "start_time": "2025-01-26T17:15:04.679462Z"
    }
   },
   "source": [
    "print(\"\\nEstadísticas descriptivas para columnas numéricas:\")\n",
    "df_raw[numerical_columns].describe()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas descriptivas para columnas numéricas:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                  x             y       azimuth      altitude      pressure\n",
       "count  2.680608e+06  2.680608e+06  2.680608e+06  2.680608e+06  2.680608e+06\n",
       "mean   3.204618e+04  1.988526e+04  1.915995e+03  5.893773e+02  2.983005e+02\n",
       "std    1.359955e+04  1.007838e+04  5.267162e+02  7.944353e+01  3.006754e+02\n",
       "min    2.215000e+03  1.000000e+01  0.000000e+00  2.200000e+02  0.000000e+00\n",
       "25%    2.138500e+04  1.169200e+04  1.750000e+03  5.400000e+02  0.000000e+00\n",
       "50%    3.353400e+04  1.498200e+04  1.890000e+03  5.800000e+02  2.690000e+02\n",
       "75%    4.572400e+04  3.054200e+04  2.060000e+03  6.300000e+02  5.480000e+02\n",
       "max    6.150400e+04  4.063000e+04  3.590000e+03  9.000000e+02  1.023000e+03"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>altitude</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.680608e+06</td>\n",
       "      <td>2.680608e+06</td>\n",
       "      <td>2.680608e+06</td>\n",
       "      <td>2.680608e+06</td>\n",
       "      <td>2.680608e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.204618e+04</td>\n",
       "      <td>1.988526e+04</td>\n",
       "      <td>1.915995e+03</td>\n",
       "      <td>5.893773e+02</td>\n",
       "      <td>2.983005e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.359955e+04</td>\n",
       "      <td>1.007838e+04</td>\n",
       "      <td>5.267162e+02</td>\n",
       "      <td>7.944353e+01</td>\n",
       "      <td>3.006754e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.215000e+03</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.200000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.138500e+04</td>\n",
       "      <td>1.169200e+04</td>\n",
       "      <td>1.750000e+03</td>\n",
       "      <td>5.400000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.353400e+04</td>\n",
       "      <td>1.498200e+04</td>\n",
       "      <td>1.890000e+03</td>\n",
       "      <td>5.800000e+02</td>\n",
       "      <td>2.690000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.572400e+04</td>\n",
       "      <td>3.054200e+04</td>\n",
       "      <td>2.060000e+03</td>\n",
       "      <td>6.300000e+02</td>\n",
       "      <td>5.480000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.150400e+04</td>\n",
       "      <td>4.063000e+04</td>\n",
       "      <td>3.590000e+03</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>1.023000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "4347fe4d",
   "metadata": {},
   "source": [
    "### Descripción de las variables numéricas y estadísticas descriptivas\n",
    "\n",
    "- **`X` y `Y`**:  \n",
    "  - Representan las coordenadas de los trazos en el plano de la tableta. Estas series de tiempo capturan cómo varían las posiciones en los ejes `X` e `Y` durante el movimiento del lápiz.  \n",
    "  - **Estadísticas descriptivas (`X`)**:  \n",
    "    - **Media (`mean`)**: 32,046.18  \n",
    "    - **Desviación estándar (`std`)**: 13,599.55  \n",
    "    - **Valor mínimo (`min`)**: 2,215  \n",
    "    - **Valor máximo (`max`)**: 61,504  \n",
    "    - **Cuartiles**:  \n",
    "      - 25%: 21,385  \n",
    "      - 50%: 33,534  \n",
    "      - 75%: 45,724  \n",
    "\n",
    "  - **Estadísticas descriptivas (`Y`)**:  \n",
    "    - **Media (`mean`)**: 19,885.26  \n",
    "    - **Desviación estándar (`std`)**: 10,078.38  \n",
    "    - **Valor mínimo (`min`)**: 1,000  \n",
    "    - **Valor máximo (`max`)**: 40,630  \n",
    "    - **Cuartiles**:  \n",
    "      - 25%: 11,692  \n",
    "      - 50%: 14,982  \n",
    "      - 75%: 30,542  \n",
    "\n",
    "- **`Azimuth`**:  \n",
    "  - Representa el ángulo entre la orientación del lápiz y una dirección de referencia en el plano de la superficie de la tableta. Este valor varía dependiendo de la inclinación horizontal del lápiz.  \n",
    "  - **Estadísticas descriptivas**:  \n",
    "    - **Media (`mean`)**: 1,915.99  \n",
    "    - **Desviación estándar (`std`)**: 526.72  \n",
    "    - **Valor mínimo (`min`)**: 0.00  \n",
    "    - **Valor máximo (`max`)**: 3,590  \n",
    "    - **Cuartiles**:  \n",
    "      - 25%: 1,750  \n",
    "      - 50%: 1,890  \n",
    "      - 75%: 2,060  \n",
    "\n",
    "- **`Altitude`**:  \n",
    "  - Captura el ángulo entre el lápiz y la superficie de la tableta. Este valor describe cómo de inclinado está el lápiz verticalmente.  \n",
    "  - **Estadísticas descriptivas**:  \n",
    "    - **Media (`mean`)**: 589.38  \n",
    "    - **Desviación estándar (`std`)**: 79.44  \n",
    "    - **Valor mínimo (`min`)**: 220  \n",
    "    - **Valor máximo (`max`)**: 900  \n",
    "    - **Cuartiles**:  \n",
    "      - 25%: 540  \n",
    "      - 50%: 580  \n",
    "      - 75%: 630  \n",
    "\n",
    "- **`Pressure`**:  \n",
    "  - Indica la presión ejercida por el lápiz al escribir sobre la superficie de la tableta.  \n",
    "  - **Estadísticas descriptivas**:  \n",
    "    - **Media (`mean`)**: 298.30  \n",
    "    - **Desviación estándar (`std`)**: 300.68  \n",
    "    - **Valor mínimo (`min`)**: 0.00  \n",
    "    - **Valor máximo (`max`)**: 1,023  \n",
    "    - **Cuartiles**:  \n",
    "      - 25%: 0.00  \n",
    "      - 50%: 269  \n",
    "      - 75%: 548  \n",
    "\n",
    "Estas estadísticas muestran las características principales de cada variable, ayudando a entender el comportamiento del trazo, la orientación del lápiz, la inclinación y la presión ejercida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13d564a2e396bf",
   "metadata": {},
   "source": [
    "### Frecuencia de valores únicos para columnas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f7dfeb722122748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:04.979858Z",
     "start_time": "2025-01-26T17:15:04.974623Z"
    }
   },
   "source": [
    "for column in categorical_columns: \n",
    "    print(\"Para {} se tienen {} valores únicos\".format(column, df[column].nunique()))\n",
    "    print(\"Que son los siguientes: \\n{}\\n\".format(df[column].value_counts()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para homework se tienen 8 valores únicos\n",
      "Que son los siguientes: \n",
      "homework\n",
      "1    258\n",
      "2    258\n",
      "3    258\n",
      "6    258\n",
      "7    258\n",
      "4    157\n",
      "5    135\n",
      "0      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Para pen_status se tienen 2 valores únicos\n",
      "Que son los siguientes: \n",
      "pen_status\n",
      "1    906\n",
      "0    682\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Para depression se tienen 25 valores únicos\n",
      "Que son los siguientes: \n",
      "depression\n",
      "4     196\n",
      "2     147\n",
      "3     132\n",
      "7     125\n",
      "5     122\n",
      "8     113\n",
      "6     110\n",
      "1      97\n",
      "9      74\n",
      "13     63\n",
      "11     61\n",
      "10     50\n",
      "0      49\n",
      "18     37\n",
      "16     28\n",
      "25     27\n",
      "17     24\n",
      "20     24\n",
      "21     24\n",
      "15     24\n",
      "14     13\n",
      "24     12\n",
      "23     12\n",
      "22     12\n",
      "19     12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Para anxiety se tienen 25 valores únicos\n",
      "Que son los siguientes: \n",
      "anxiety\n",
      "2     157\n",
      "6     148\n",
      "7     147\n",
      "5     112\n",
      "8      98\n",
      "4      97\n",
      "3      97\n",
      "9      86\n",
      "1      85\n",
      "13     76\n",
      "0      64\n",
      "11     61\n",
      "10     60\n",
      "16     51\n",
      "12     50\n",
      "15     39\n",
      "14     37\n",
      "20     24\n",
      "22     24\n",
      "17     14\n",
      "25     13\n",
      "19     12\n",
      "31     12\n",
      "18     12\n",
      "27     12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Para stress se tienen 33 valores únicos\n",
      "Que son los siguientes: \n",
      "stress\n",
      "16    112\n",
      "14    110\n",
      "8     108\n",
      "15    100\n",
      "6      96\n",
      "13     85\n",
      "11     76\n",
      "17     76\n",
      "9      75\n",
      "19     65\n",
      "5      60\n",
      "18     60\n",
      "4      60\n",
      "20     50\n",
      "7      50\n",
      "3      48\n",
      "12     38\n",
      "27     38\n",
      "2      37\n",
      "10     36\n",
      "28     36\n",
      "21     26\n",
      "22     24\n",
      "23     13\n",
      "0      13\n",
      "1      12\n",
      "31     12\n",
      "32     12\n",
      "30     12\n",
      "39     12\n",
      "35     12\n",
      "25     12\n",
      "24     12\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "c558d3a93dc89204",
   "metadata": {},
   "source": [
    "### Verificación de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "id": "2b0e6f32602b92b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:05.013345Z",
     "start_time": "2025-01-26T17:15:04.980864Z"
    }
   },
   "source": [
    "print(\"\\nValores faltantes en el conjunto de datos:\")\n",
    "df_raw.isnull().sum()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores faltantes en el conjunto de datos:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x             0\n",
       "y             0\n",
       "timestamp     0\n",
       "pen_status    0\n",
       "azimuth       0\n",
       "altitude      0\n",
       "pressure      0\n",
       "homework      0\n",
       "Subject       0\n",
       "depression    0\n",
       "anxiety       0\n",
       "stress        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "4922ee9d",
   "metadata": {},
   "source": [
    "Por la naturaleza del set de datos, al ser datos recolectados por expertos que requerían realizar ejercicios manuales y repetirse en caso de que no se completar el ejercicio, nuestro set de datos no tiene ningún valor nulo.\n",
    "\n",
    "Esto significa que no es necesario implementar algún método o algoritmo que nos ayude a llenar los datos nulos.\n",
    "\n",
    "Sin embargo observamos que existen 6 casos de tareas que no están clasificadas dentro de una categoría dada. Por el momento no se eliminarán ya que representan el 0.37% de los datos. Al ser mínimo determinaremos si causan un impacto al modelo de clasificación más adelante."
   ]
  },
  {
   "cell_type": "code",
   "id": "899033fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:05.018350Z",
     "start_time": "2025-01-26T17:15:05.013345Z"
    }
   },
   "source": [
    "float(df['homework'].value_counts()[0]/df['homework'].shape[0]*100)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3778337531486146"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "3b4edf7cde5a536c",
   "metadata": {},
   "source": [
    "## Análisis de Univariante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f58a203b36db12",
   "metadata": {},
   "source": [
    "### Visualizaciones para Datos Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "id": "17cecec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:15:05.023265Z",
     "start_time": "2025-01-26T17:15:05.018854Z"
    }
   },
   "source": [
    "def make_countplot(df, column_names, bins=10, fig_size=(10,20)):\n",
    "  plt.figure(figsize=fig_size, constrained_layout=True)\n",
    "  for idx,column_name in enumerate(column_names):\n",
    "    ax = plt.subplot(len(column_names)//2+1, 3,idx+1)\n",
    "    sns.countplot(df, x=column_name)\n",
    "    ax.set_title(column_name)\n",
    "  plt.show()\n",
    "\n",
    "def make_hist_plot(df, column_names, bins=10, fig_size=(10,20)):\n",
    "  plt.figure(figsize=fig_size, constrained_layout=True)\n",
    "  for idx,column_name in enumerate(column_names):\n",
    "    ax = plt.subplot(len(column_names)//2+1, 3,idx+1)\n",
    "    df[column_name].hist(bins=bins)\n",
    "    ax.set_title(column_name)\n",
    "  plt.show()"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "50244fd25b7c013c",
   "metadata": {},
   "source": [
    "#### Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "id": "87840da4f552e595",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-26T17:15:05.023265Z"
    }
   },
   "source": [
    "for col in numerical_columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(df_raw[col], kde=True, bins=30)\n",
    "    plt.title(f\"Distribución de {col}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a7ae963",
   "metadata": {},
   "source": [
    "**Descripción de los histogramas:**\n",
    "\n",
    "\n",
    "- **Distribución de la variable ´x´**:\n",
    "    - **Multimodalidad:** La distribución muestra múltiples picos, indicando la presencia de varias subpoblaciones o grupos distintos.\n",
    "    - **Sesgo:** Algunos picos son asimétricos, aunque la distribución general parece balanceada entre grupos.\n",
    "    - **Curtosis:** Moderada, con picos definidos pero sin colas excesivamente largas o planas.\n",
    "    - **Dispersión:** Amplio rango de valores entre 0 y 60,000, lo que indica alta variabilidad.\n",
    "    - **Colas:** No se observan colas extremas, sugiriendo pocos o ningún outlier significativo.\n",
    "\n",
    "\n",
    "- **Distribución de la variable ´y´**:\n",
    "    - **Multimodalidad:** La distribución presenta dos picos principales, indicando dos grupos o subpoblaciones claras.\n",
    "    - **Sesgo:** El primer pico parece ligeramente sesgado hacia la derecha, mientras que el segundo está más balanceado.\n",
    "    - **Curtosis:** Moderada, con un primer pico pronunciado y un segundo menos definido.\n",
    "    - **Dispersión:** Los valores están contenidos entre 0 y 40,000, con mayor concentración entre 10,000 y 15,000, y otro grupo entre 30,000 y 35,000.\n",
    "    - **Colas:** Las colas no son extremadamente largas, pero hay una pequeña disminución gradual hacia los extremos.\n",
    "\n",
    "\n",
    "- **Distribución de la variable ´azimuth´**:\n",
    "  - **Multimodalidad:** La distribución es predominantemente unimodal, con un pico central bien definido alrededor de 2000, aunque hay pequeñas concentraciones en los extremos.\n",
    "  - **Sesgo:** La distribución parece simétrica alrededor del pico principal, sin sesgo significativo.\n",
    "  - **Curtosis:** Alta, con un pico central estrecho y pronunciado, lo que indica una concentración significativa de valores alrededor del centro.\n",
    "  - **Dispersión:** Los valores están concentrados principalmente entre 1500 y 2500, con caídas graduales hacia los extremos en un rango de 0 a 3600.\n",
    "  - **Colas:** Las colas son relativamente cortas, con una ligera presencia de valores hacia los extremos izquierdo y derecho.\n",
    "\n",
    "\n",
    "- **Distribución de la variable ´altitude´**:\n",
    "  - **Multimodalidad:** La distribución es principalmente unimodal, con un pico definido alrededor de 600, aunque hay pequeñas fluctuaciones en los alrededores del pico principal.\n",
    "  - **Sesgo:** Ligeramente sesgada hacia la derecha, con una caída más gradual en los valores altos (700-900) comparado con los valores bajos.\n",
    "  - **Curtosis:** Moderada, con un pico relativamente pronunciado en el centro y una dispersión gradual hacia los extremos.\n",
    "  - **Dispersión:** Los valores están concentrados principalmente entre 500 y 700, con un rango total de aproximadamente 200 a 900.\n",
    "  - **Colas:** Las colas son visibles pero no extremadamente largas, indicando pocos valores extremos fuera del rango principal.\n",
    "\n",
    "\n",
    "- **Distribución de la variable ´pressure´**:\n",
    "  - **Multimodalidad:** La distribución es principalmente unimodal, con una alta concentración de valores en el rango más bajo (cercano a 0), seguida de una larga cola que se extiende hacia valores más altos.\n",
    "  - **Sesgo:** Fuertemente sesgada hacia la derecha, con la mayor densidad concentrada en valores cercanos a 0.\n",
    "  - **Curtosis:** Alta, con un pico extremo en valores bajos y una dispersión muy gradual hacia el resto del rango.\n",
    "  - **Dispersión:** Los valores están distribuidos en un rango amplio de 0 a 1000, pero la mayoría se encuentra muy cerca de 0.\n",
    "  - **Colas:** Una cola larga y extendida hacia la derecha, lo que indica la presencia de valores más altos que ocurren con menor frecuencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a74a62b858ecd25",
   "metadata": {},
   "source": [
    "#### Diagramas de Caja"
   ]
  },
  {
   "cell_type": "code",
   "id": "1706d8f494c884c9",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "for col in numerical_columns:\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    sns.boxplot(x=df_raw[col])\n",
    "    plt.title(f\"Diagrama de Caja de {col}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0fbe08c5",
   "metadata": {},
   "source": [
    "**Descripción de los diagramas de caja:** \n",
    "\n",
    "- **Descripción del boxplot de `x`**\n",
    "\n",
    "  - **Mediana:** La línea central dentro de la caja está cercana a los 33,534, lo cual coincide con el valor reportado como mediana en las estadísticas.\n",
    "  - **Rango intercuartílico (IQR):** La caja abarca de aproximadamente 21,385 (Q1) a 45,724 (Q3), lo que indica un amplio rango para los valores centrales del 50% de los datos.\n",
    "  - **Simetría:** Los bigotes son casi simétricos respecto a la mediana, sugiriendo una distribución relativamente balanceada sin un sesgo extremo.\n",
    "  - **Outliers:** No se observan puntos fuera de los bigotes, indicando que no hay valores atípicos significativos detectados en los datos.\n",
    "  - **Dispersión:** Los bigotes se extienden desde aproximadamente 2,215 (mínimo) hasta 61,504 (máximo), mostrando una alta dispersión en los valores de la variable.\n",
    "\n",
    "\n",
    "- **Descripción de boxplot de `y`**\n",
    "   - **Mediana:** La línea central dentro de la caja está cerca de los 14,982, indicando que la mitad de los datos se encuentra por debajo de este valor.\n",
    "  - **Rango intercuartílico (IQR):** La caja abarca desde aproximadamente 11,692 (Q1) hasta 30,542 (Q3), mostrando una dispersión amplia en los datos centrales del 50%.\n",
    "  - **Simetría:** Los bigotes son ligeramente más largos hacia el lado derecho, lo que sugiere un sesgo positivo en la distribución.\n",
    "  - **Outliers:** No se observan puntos fuera de los bigotes en este gráfico, aunque los valores cercanos al máximo podrían analizarse más detalladamente como potenciales outliers.\n",
    "  - **Dispersión:** Los datos están distribuidos en un rango que va desde 10 (mínimo) hasta 40,630 (máximo), con una mayor densidad entre Q1 y Q3.\n",
    "\n",
    "- **Descripción del boxplot de `azimuth`**\n",
    "    - **Mediana:** La línea central dentro de la caja está cerca de los 1,890, lo que indica que la mitad de los datos se encuentra por debajo de este valor.\n",
    "    - **Rango intercuartílico (IQR):** La caja abarca desde aproximadamente 1,750 (Q1) hasta 2,060 (Q3), mostrando una concentración significativa de valores en este rango.\n",
    "    - **Simetría:** Los bigotes son relativamente equilibrados, aunque se extienden más hacia los valores extremos (0 y 3,590).\n",
    "    - **Outliers:** Hay puntos identificados fuera de los bigotes, tanto en el extremo inferior (cercanos a 0) como en el extremo superior (cercanos a 3,590), lo que indica la presencia de valores atípicos.\n",
    "    - **Dispersión:** La mayor densidad de datos se concentra en el rango entre Q1 y Q3, mientras que los valores extremos se distribuyen de manera más dispersa hacia los límites del rango total.\n",
    "\n",
    "- **Descripción del boxplot de `altitude`**\n",
    "    - **Mediana:** La línea central dentro de la caja está cerca de los 580, indicando que la mitad de los datos está distribuida de manera equilibrada en torno a este valor.\n",
    "    - **Rango intercuartílico (IQR):** La caja abarca desde aproximadamente 540 (Q1) hasta 630 (Q3), lo que muestra una concentración significativa de datos dentro de este rango.\n",
    "    - **Simetría:** Los bigotes son asimétricos, extendiéndose más hacia el extremo inferior que hacia el superior, lo que indica un sesgo leve hacia los valores bajos.\n",
    "    - **Outliers:** Se observan puntos fuera de los bigotes tanto en los extremos inferiores (cercanos a 200) como superiores (cercanos a 900), lo que identifica valores atípicos significativos.\n",
    "    - **Dispersión:** La mayoría de los datos están concentrados dentro del rango intercuartílico, con una dispersión moderada hacia los valores extremos.\n",
    "\n",
    "- **Descripción del boxplot de `pressure`**\n",
    "    - **Mediana:** La línea central dentro de la caja está cerca de los 269, indicando que la mitad de los valores de presión está por debajo de este punto.\n",
    "    - **Rango intercuartílico (IQR):** La caja abarca desde aproximadamente 0 (Q1) hasta 548 (Q3), mostrando que una gran proporción de los datos está concentrada en este rango.\n",
    "    - **Simetría:** Los bigotes son notablemente asimétricos, extendiéndose mucho más hacia el lado superior, lo que refleja una distribución sesgada positivamente.\n",
    "    - **Outliers:** No se identifican puntos fuera de los bigotes, lo que sugiere que no hay valores atípicos significativos.\n",
    "    - **Dispersión:** Aunque el rango de valores va desde 0 hasta 1,023, la mayor concentración se encuentra dentro del IQR, mientras que los valores altos están más dispersos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ce304",
   "metadata": {},
   "source": [
    "Dado que estamos trabajando con series de tiempo y que los datos se procesarán de esta forma, es más util observar la distribución temporal de los datos así como el equivalente a lo que sería un diagrama de caja de forma temporal. Esto nos indica valores máximos, mínimos, quartiles y media para cada sample tiempo."
   ]
  },
  {
   "cell_type": "code",
   "id": "b17035fa",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def sample_windows(data, homework, variable, samples=2):\n",
    "    sample = data[data['homework']==homework]['x'].sample(n=samples)\n",
    "    return sample\n",
    "\n",
    "def plot_random_signals(df, variable, title, homework, samples=3):\n",
    "    layout = go.Layout(title=title,\n",
    "        xaxis=dict(title='Timestamp'),\n",
    "        yaxis=dict(title='Value'),\n",
    "        hovermode='closest'\n",
    "    )\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter(x=list(range(len(data))), y=data, mode='lines', name='Sample {}') for data in sample_windows(df, homework=homework, variable=variable, samples=samples)\n",
    "    ], layout=layout)\n",
    "    fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "79493866",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "plot_random_signals(df, 'x', 'X signals for 3 random samples of homework 1', homework=1, samples=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f71985d0",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "plot_random_signals(df, 'y', 'Y signals for 3 random samples of homework 1', homework=3, samples=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a2d567d",
   "metadata": {},
   "source": [
    "Como puede observarse, las variables temporales tanto de X como Y no tienen la misma cantidad de samples. Esto se debe a que los datos fueron recolectados de diferentes personas que dibujaron de manera distinta y tiempos distintos. A continuación se puede observar que para X y Y las longitudes varían y tienen las siguientes características de acuerdo con su longitud."
   ]
  },
  {
   "cell_type": "code",
   "id": "a41264ba",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df['x'].apply(lambda x: len(x)).describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "065aedb1",
   "metadata": {},
   "source": [
    "Los ejemplos tienen una media de 1688 samples, el que menos samples tiene 2 y el que más tiene son 10,136 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093476cb",
   "metadata": {},
   "source": [
    "#### Distribución de datos de señales de series de tiempo (min, max, media, quantiles 25% y 75%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c8e9a",
   "metadata": {},
   "source": [
    "A continuación se muestran los rangos máximos y mínimos para los diferentes instantes de tiempo de las señales numéricas, así como la media y los quantiles 25% y 75%. Puede observarse que el valor los valores colisionan porque pocos dibujos tienen una longitud mayor a 8000 muestras, en estos casos las métricas de maximo, mínimo y media dan el mismo valor al ser la única muestra disponible."
   ]
  },
  {
   "cell_type": "code",
   "id": "a55bf353",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def plot_ranges(variable):\n",
    "    data = df[variable].apply(pd.Series)\n",
    "    quantiles = data.quantile([0.25, 0.75], axis=0)\n",
    "    plt.plot(data.max(axis=0), label='Max')\n",
    "    plt.plot(quantiles.iloc[1], label='75%')\n",
    "    plt.plot(quantiles.mean(axis=0), label='Mean')\n",
    "    plt.plot(quantiles.iloc[0], label='25%')\n",
    "    plt.plot(data.min(axis=0), label='Min')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(f\"Range of variable '{variable}'\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43ed728f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "for x in numerical_columns:\n",
    "    plot_ranges(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "729d3b0e",
   "metadata": {},
   "source": [
    "Podemos obtener los valores máximos y mínimos para las señales, en especial las señales X y Y tienen valores del orden de decenas de miles pues representan coordenadas. Es probable que debamos normalizar las señales para que sus valores queden entre 0 y 1 para tenerlos listos para los algoritmos de clasificación basados en redes neuronales recurrentes. Por otro lado, si lo que se quiere es utilizar las imágenes generadas por las coordenadas será necesario mantenerlas tal y como están. En el preprocesamiento se utilizan ambas alternativas, se normalizan las señales y se dejan las originales X y Y disponibles de igual forma."
   ]
  },
  {
   "cell_type": "code",
   "id": "c2c200cf",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "for var_name in numerical_columns:\n",
    "    print(f\"Max '{var_name}':\", df[var_name].apply(pd.Series).max().max())\n",
    "    print(f\"Min '{var_name}':\", df[var_name].apply(pd.Series).min().min())\n",
    "    print(\"\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1da2b516",
   "metadata": {},
   "source": [
    "### Visualizaciones para Datos Categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba5067",
   "metadata": {},
   "source": [
    "#### **Gráfico de conteo**"
   ]
  },
  {
   "cell_type": "code",
   "id": "721c122a",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "make_countplot(df, categorical_columns, fig_size=(10,8))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d8c5596c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "for column in categorical_columns: \n",
    "    print(\"Para {} se tienen {} valores únicos\".format(column, df[column].nunique()))\n",
    "    print(\"Que son los siguientes: \\n{}\\n\".format(df[column].value_counts()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cef96964",
   "metadata": {},
   "source": [
    "**Descripción de los Countplots**\n",
    "\n",
    "1. **`homework`**:\n",
    "   - **Valores únicos**: 8\n",
    "   - **Distribución de los valores**:  \n",
    "     - Los valores 1, 2, 3, 6, y 7 tienen el mismo recuento (258), lo que sugiere una distribución uniforme para estos niveles.  \n",
    "     - El valor 4 tiene un recuento menor (157), mientras que el 5 (135) y el 0 (6) son valores poco frecuentes.  \n",
    "   - **Interpretación del Countplot**:  \n",
    "     - Este gráfico mostrará barras significativamente más altas para los valores más comunes (1, 2, 3, 6, 7) y barras mucho más pequeñas para los valores menos comunes (4, 5, 0).  \n",
    "     - Los valores altos indican que la mayoría de los datos están concentrados en ciertos niveles de tarea (`homework`).\n",
    "\n",
    "2. **`pen_status`**:\n",
    "   - **Valores únicos**: 2 (0 y 1)\n",
    "   - **Distribución de los valores**:  \n",
    "     - El valor 1 tiene un recuento de 906, mientras que el 0 tiene 682.  \n",
    "   - **Interpretación del Countplot**:  \n",
    "     - Este gráfico mostrará solo dos barras, con la barra correspondiente al valor 1 siendo más alta que la del valor 0.  \n",
    "     - Esto sugiere que el estado 1 de la pluma ocurre con mayor frecuencia que el estado 0.\n",
    "\n",
    "3. **`depression`**:\n",
    "   - **Valores únicos**: 25\n",
    "   - **Distribución de los valores**:  \n",
    "     - Los valores más comunes son 4 (196), 2 (147), y 3 (132).  \n",
    "     - Los valores menos comunes son los últimos de la lista, como 24, 23, 22, 19, y 25, todos con un recuento de 12.  \n",
    "   - **Interpretación del Countplot**:  \n",
    "     - Este gráfico mostrará una alta variabilidad entre las barras. Las barras correspondientes a los valores 4, 2, y 3 serán las más altas, mientras que habrá muchas barras pequeñas para valores menos frecuentes.  \n",
    "     - La distribución indica que los niveles de depresión están dispersos en varios niveles, pero ciertos valores son más frecuentes.\n",
    "\n",
    "4. **`anxiety`**:\n",
    "   - **Valores únicos**: 25\n",
    "   - **Distribución de los valores**:  \n",
    "     - Los valores más comunes son 2 (157), 6 (148), y 7 (147).  \n",
    "     - Los valores menos comunes incluyen 25, 19, 31, 18, y 27, todos con un recuento de 12 o menor.  \n",
    "   - **Interpretación del Countplot**:  \n",
    "     - Similar al caso de `depression`, el gráfico tendrá barras altas para los valores más comunes y barras mucho más bajas para los menos frecuentes.  \n",
    "     - La distribución sugiere una alta variabilidad en los niveles de ansiedad, con una concentración en algunos valores específicos.\n",
    "\n",
    "5. **`stress`**:\n",
    "   - **Valores únicos**: 33\n",
    "   - **Distribución de los valores**:  \n",
    "     - Los valores más comunes son 16 (112), 14 (110), y 8 (108).  \n",
    "     - Los valores menos comunes incluyen 1, 31, 32, 30, 39, 35, 25, y 24, todos con un recuento de 12 o menor.  \n",
    "   - **Interpretación del Countplot**:  \n",
    "     - Este gráfico mostrará barras muy altas para los valores más comunes, con una disminución gradual en la altura de las barras hacia los valores menos comunes.  \n",
    "     - La amplia cantidad de valores únicos indica una distribución más dispersa y variada en los niveles de estrés.\n",
    "\n",
    "**Observaciones Generales**\n",
    "\n",
    "- Las variables como `homework` y `pen_status` tienen pocos valores únicos, lo que da lugar a gráficos más simples y menos variables.\n",
    "- Las variables `depression`, `anxiety`, y `stress` tienen una mayor cantidad de valores únicos, lo que se traduce en gráficos más complejos con una distribución más dispersa.\n",
    "- Los countplots ayudan a visualizar la frecuencia relativa de cada categoría y permiten identificar patrones de concentración o dispersión de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535900e9b87d7c93",
   "metadata": {},
   "source": [
    "## Análisis Bivariado y Multivariado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e43438822c165a",
   "metadata": {},
   "source": [
    "### Análisis de Correlación para Variables Numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad6c5dc66d3655",
   "metadata": {},
   "source": [
    "#### Matriz de Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8e513",
   "metadata": {},
   "source": [
    "Para incluir en la matriz de correlación las variables categóricas haremos one-hot encoding de las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "id": "49a3b687",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df_raw['depression'] = df_raw['depression'].astype(int)\n",
    "df_raw['anxiety'] = df_raw['anxiety'].astype(int)\n",
    "df_raw['stress'] = df_raw['stress'].astype(int)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "213aa230",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Compute correlation coefficient\n",
    "correlation = df_raw[numerical_columns + categorical_columns].corr()\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c832ded3",
   "metadata": {},
   "source": [
    "**Descripción de la matriz de correlación**\n",
    "\n",
    "- La matriz muestra las correlaciones entre distintas variables del conjunto de datos. Las correlaciones más fuertes, positivas o negativas, se destacan con colores más cercanos al rojo o azul respectivamente, mientras que las correlaciones cercanas a 0 son más claras.\n",
    "- **Observaciones destacadas:**\n",
    "  - Existe una correlación negativa fuerte entre `x` y `homework` (-0.87).\n",
    "  - La variable `pen_status` tiene una correlación positiva alta con `pressure` (0.82).\n",
    "  - Variables relacionadas con emociones, como `depression`, `anxiety` y `stress`, tienen correlaciones moderadas entre sí (valores entre 0.59 y 0.73).\n",
    "  - La mayoría de las correlaciones entre variables como `azimuth`, `altitude`, `pressure` y las emocionales son bajas o cercanas a 0, lo que indica poca relación entre ellas.\n",
    "\n",
    "**Nota importante:**\n",
    "Dado que se trata de un análisis aplicado a series de tiempo, estas correlaciones deben interpretarse con precaución. Las relaciones identificadas en esta matriz podrían no ser relevantes debido a la naturaleza temporal de los datos. En lugar de este análisis estático, podría ser más apropiado utilizar técnicas específicas para series de tiempo, como autocorrelación o análisis de dependencia temporal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39705f9553f0fd1e",
   "metadata": {},
   "source": [
    "#### Pairplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770a760e2fbb64b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T00:25:49.808437Z",
     "start_time": "2025-01-24T00:25:49.016427Z"
    }
   },
   "source": [
    "No es recomendable utilizar sns.pairplot para analizar series de tiempo, ya que está diseñado para visualizar relaciones entre variables estáticas (no dependientes del tiempo). Las series de tiempo tienen una estructura secuencial donde el orden de los datos es crucial, y un pairplot no captura esta dependencia temporal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd39cbed0d399243",
   "metadata": {},
   "source": [
    "## Visualización gráfica de las tareas"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb74683990dc245b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Expandir columnas con listas en filas separadas\n",
    "df_expanded = df.explode(['x', 'y', 'timestamp', 'azimuth', 'altitude', 'pressure']).reset_index()\n",
    "\n",
    "# Convertir columnas expandidas a numéricas\n",
    "for col in ['x', 'y', 'timestamp', 'azimuth', 'altitude', 'pressure']:\n",
    "    df_expanded[col] = pd.to_numeric(df_expanded[col])\n",
    "\n",
    "# Mostrar las primeras filas del conjunto de datos expandido\n",
    "df_expanded.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cacfb63d365ab5fa",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def plot_subject_data(subject_id, pen_status, homework_id, x_size=5, y_size=5):\n",
    "    \"\"\"\n",
    "    Función para graficar datos de dispersión para un sujeto específico,\n",
    "    con un estado de lápiz y una tarea específicos.\n",
    "\n",
    "    Parámetros:\n",
    "    subject_id (int): ID del sujeto.\n",
    "    pen_status (int): Estado del lápiz (activo/inactivo).\n",
    "    homework_id (int): ID de la tarea.\n",
    "    \"\"\"\n",
    "    # Filtrar los datos\n",
    "    sample_subject_data = df_expanded[(df_expanded['Subject'] == subject_id) &\n",
    "                                      (df_expanded['pen_status'] == pen_status) &\n",
    "                                      (df_expanded['homework'] == homework_id)]\n",
    "\n",
    "    # Verificar si los datos filtrados no están vacíos\n",
    "    if not sample_subject_data.empty:\n",
    "        # Crear el gráfico de dispersión\n",
    "        plt.figure(figsize=(x_size, y_size))\n",
    "        plt.scatter(-sample_subject_data['y'], sample_subject_data['x'], s=3, c='blue', alpha=0.6)\n",
    "        plt.title(f\"Gráfico de Dispersión: Sujeto {subject_id}, Estado del Lápiz {pen_status}, Tarea {homework_id}\")\n",
    "        plt.xlabel(\"Posición -y\")\n",
    "        plt.ylabel(\"Posición x\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No se encontraron datos para Sujeto {subject_id}, Estado del Lápiz {pen_status}, Tarea {homework_id}.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "66aa7635cfb08525",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "for homework_id in range(1, 7):\n",
    "    plot_subject_data(subject_id=1, pen_status=1, homework_id=homework_id)\n",
    "\n",
    "plot_subject_data(subject_id=1, pen_status=1, homework_id=7, x_size=12, y_size=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "57c26f9d83eb1896",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41da7156859c4eb",
   "metadata": {},
   "source": [
    "### Manejo de Valores Faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc89423cc41a44",
   "metadata": {},
   "source": [
    "No hay datos faltantes en el conjunto de datos. Nuevamente, como se había mencionado, no hay necesidad de realizar alguna técnica o algoritmo para datos faltantes en nuestro set de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9d075",
   "metadata": {},
   "source": [
    "### Tratamiento de variables categóricas\n",
    "\n",
    "Las variables categóricas 'homework' y 'pen_status' no representan características que puedan aportar valor predictivo sobre las situaciones de depresión, ansiedad o estrés. Más bien representan metadatos o información que permite filtrar los datos para su gestión. Las variables como 'homework' y 'pen_status' tienen baja cardinalidad lo que implicaría el uso de one-hot encoding, sin embargo no serán preprocesadas pues serán utilizadas como método de filtrado no para el entrenamiento de los algoritmos.\n",
    "\n",
    "Por otro lado las etiquetas como 'depression', 'anxiety' y 'stress' ya se encuentran codificadas en forma de one-hot encoding desde que los datos se preparon con base en el paper Nolazco-Flores, et al. (2021). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840f87e",
   "metadata": {},
   "source": [
    "### Tratamiento de variables numéricas\n",
    "\n",
    "En el caso de las variables numéricas de series de tiempo, éstas aportan el poder predictivo. Dado que se utilizarán modelos basados en redes neuronales, las características con magnitudes mayores pueden sesgar la predicción. Por esta razón se utilizará una normalización aplicada a series de tiempo. Dado que estamos tratando con series de tiempo implementaremos un transformador de scikit-learn con la capacidad de guardar los parámetros para la reproducción en posteriores etapas. \n",
    "\n",
    "En el caso de los outliers en este caso no se removerán pues no representan valores individuales, sino que son parte de la señales de series de tiempo y representan ángulos de azimuth y altitude fuera de lo normal, esto podría aportar valor predictivo. Lo que si será necesario es normalizar estos datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3a7c8",
   "metadata": {},
   "source": [
    "Ahora comparando ambos datos podemos ver los cambios dentro de los sesgos, los originales por lo general están sesgados a la izquierda, mientras que con los nuevos cambios se estandarizan más los valores, y prácticamente eliminado los valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "id": "7b16d9a8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "class StandardScalerArray(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Custom scikit transformer for scaling time-series using z-score, it allows to save a rolling mean and std-dev for training dataset, \n",
    "    so the whole preprocessing pipeline can be replicated during inference in development and production. It makes it repeatable and scalable.\n",
    "    '''\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.column_names = list(X.columns)\n",
    "\n",
    "        # state\n",
    "        self.mean_of_means = {column_name: 0 for column_name in self.column_names} # means for each feature column\n",
    "        self.stddev = {column_name: 1 for column_name in self.column_names} # mean stddev for each feature column\n",
    "        self.samples_count = {column_name: 1 for column_name in self.column_names} # count for each column\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # perform z-score transformation \n",
    "        \n",
    "        return X.apply(self._batch_normalize)\n",
    "    \n",
    "    def _normalize_series(self, window, column_name):\n",
    "        mean = window.mean()\n",
    "        stddev = window.std() + 1E-9 # avoid division by zero\n",
    "\n",
    "        samples_count = self.samples_count[column_name]\n",
    "\n",
    "        self.mean_of_means[column_name] = (self.mean_of_means[column_name] + samples_count * mean)/(samples_count + 1)\n",
    "        self.stddev[column_name] = (self.stddev[column_name] + samples_count * stddev)/(samples_count + 1)\n",
    "        self.samples_count[column_name] += 1\n",
    "\n",
    "        return (window - self.mean_of_means[column_name]) / self.stddev[column_name]\n",
    "\n",
    "    def _batch_normalize(self, column):\n",
    "        return column.map(lambda col_val: self._normalize_series(col_val, column.name))\n",
    "    \n",
    "    def get_feature_names_out(self, column_names):\n",
    "        return self.column_names\n",
    "\n",
    "\n",
    "std_scaler_array = StandardScalerArray()\n",
    "\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('normalization', std_scaler_array, numerical_columns)\n",
    "], remainder='passthrough')\n",
    "col_transformer\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1286d07d",
   "metadata": {},
   "source": [
    "Previo a la transformación haremos una división de los datos en entrenamiento, validación y prueba para evitar el filtrado de información. Se utilizarán 70%, 15% y 15% de los datos respectivamente. Se utilizará la estratificación a partir de las variables de 'depression', 'anxiety' y 'stress'."
   ]
  },
  {
   "cell_type": "code",
   "id": "9bd0b0c0",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df.drop(columns=['timestamp', 'depression', 'anxiety', 'stress']), df[['depression','anxiety','stress']], test_size=0.7, random_state=42, stratify=df[['depression','anxiety','stress']])\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp[['depression','anxiety','stress']])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bdff2bcd",
   "metadata": {},
   "source": [
    "Almacenamos los conjuntos generados para su reutilización posterior"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3f7b034",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "X_train.to_parquet('../data/raw_binary/X_train.parquet')\n",
    "y_train.to_parquet('../data/raw_binary/y_train.parquet')\n",
    "X_val.to_parquet('../data/raw_binary/X_val.parquet')\n",
    "y_val.to_parquet('../data/raw_binary/y_val.parquet')\n",
    "X_test.to_parquet('../data/raw_binary/X_test.parquet')\n",
    "y_test.to_parquet('../data/raw_binary/y_test.parquet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae490749",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df_normalized = col_transformer.fit_transform(X_train)\n",
    "column_names = [x.split('__')[-1] for x in col_transformer.get_feature_names_out()] # get column names back again\n",
    "X_train_normalized = pd.DataFrame(df_normalized, columns=column_names) # transformer generates matrix, convert back to dataframe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aead3aa6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "X_train_normalized"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4cd72739",
   "metadata": {},
   "source": [
    "A continuación se muestran las señales normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "id": "f0b56fbb",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "plot_random_signals(X_train_normalized, 'x', 'Normalized X signals for 3 random samples of homework 1', homework=1, samples=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c607fadb",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "plot_random_signals(X_train_normalized, 'y', 'Normalized X signals for 3 random samples of homework 1', homework=1, samples=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c55d5a07",
   "metadata": {},
   "source": [
    "### **Aplicación de transformación wavelet (WDT)**\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ba5858e6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "class WaveletTransformer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Custom scikit transformer for wavelet transformation of time-series data.\n",
    "    '''\n",
    "\n",
    "    def _extract_wavelet_features(self, data_list, wavelet='db4', level=10):\n",
    "        \"\"\"\n",
    "        Aplicar la Transformada Wavelet a una lista de datos y extraer características.\n",
    "\n",
    "        Parámetros:\n",
    "        data_list = lista de datos a usar.\n",
    "        wavelet = transformacion wavelet a usar (Daubechies 4 wavelet)\n",
    "        level = número de veces que se realiza el proceso de descomposición en una señal o imagen\n",
    "        \"\"\"\n",
    "        coeffs = pywt.wavedec(data_list, wavelet, level=level)\n",
    "        features = []\n",
    "        for coef in coeffs:\n",
    "            features.extend([\n",
    "                np.mean(coef),\n",
    "                np.std(coef),\n",
    "                np.min(coef),\n",
    "                np.max(coef)\n",
    "            ])\n",
    "        return features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        self.column_names = list(X.columns)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.apply(self._batch_process)\n",
    "    \n",
    "    def _apply_transformation(self, window, column_name):\n",
    "        return self._extract_wavelet_features(window)\n",
    "\n",
    "\n",
    "    def _batch_process(self, column):\n",
    "        return column.map(lambda col_val: self._apply_transformation(col_val, column.name))\n",
    "    \n",
    "    def get_feature_names_out(self, column_names):\n",
    "        return self.column_names\n",
    "\n",
    "\n",
    "wavelet_transformer = WaveletTransformer()\n",
    "\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('wavelet', wavelet_transformer, numerical_columns)\n",
    "], remainder='passthrough')\n",
    "col_transformer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8f4719d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df_wavelet = col_transformer.fit_transform(X_train)\n",
    "column_names = [x.split('__')[-1] for x in col_transformer.get_feature_names_out()] # get column names back again\n",
    "X_train_wavelet = pd.DataFrame(df_wavelet, columns=column_names) # transformer generates matrix, convert back to dataframe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "564aeb36",
   "metadata": {},
   "source": [
    "**Ejemplo de aplicación wavelet a la columna de series de tiempo X**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e365a4d",
   "metadata": {},
   "source": [
    "Se puede observar que las señales han pasado del dominio del tiempo a una representación en componentes. Esto será útil para las técnicas de clasificación que utilizaremos más adelante, sin embargo será necesario ajustar los parámetros de la conversión conforme se haga más progreso en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "id": "17be9e52",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "sns.histplot(X_train_wavelet['x'].iloc[451])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11620127",
   "metadata": {},
   "source": [
    "**Preguntas a contestar despues de abordar el EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5371f5",
   "metadata": {},
   "source": [
    "**¿Hay valores faltantes en el conjunto de datos? ¿Se pueden identificar patrones de ausencia?**\n",
    "\n",
    "R: El set de datos no tiene ningún conjunto de datos faltantes\n",
    "\n",
    "**¿Cuáles son las estadísticas resumidas del conjunto de datos?**\n",
    "**¿Hay valores atípicos en el conjunto de datos?**\n",
    "\n",
    "R: Sabemos que existen un máximo de 7 tareas existentes en la columna de **tareas**, el estatus de la pluma son valores de 0 y 1, donde existen ligeramente mas valores en 1, X y Y son nuestras coordenadas de x y y de la escritura sobre tiempo, **Azimut** es el ángulo, generalmente medido en grados, entre la dirección de un objeto (o señal) y una dirección de referencia, la **altitud** se refiere al ángulo entre el lápiz y la superficie de la tableta, La **presión** es la presión obtenida en la escritura y nuestras etiquetas serían los valores designados a las emociones como **depresión, ansiedad y estrés**\n",
    "\n",
    "Las únicos datos que actualmente parecen tener datos sesgados, serian las etiquetas ya que los resultados varían bastante dependiendo de la ejecución de los usuarios, a diferencia de los datos obtenidos a través del tiempo, esto es algo observable en las tablas obtenidas dentro del documento.\n",
    "\n",
    "**¿Cuál es la cardinalidad de las variables categóricas?**\n",
    "\n",
    "*   Cardinalidad:\n",
    "*   Tareas: 8\n",
    "*   Estatus de pluma: 2\n",
    "*   Depresión: 25\n",
    "*   Ansiedad: 25\n",
    "*   Estrés: 33\n",
    "\n",
    "**¿Existen distribuciones sesgadas en el conjunto de datos?**\n",
    "\n",
    "R: Las únicos datos que actualmente parecen tener datos sesgados, serian las etiquetas.\n",
    "\n",
    "**¿Se identifican tendencias temporales? (En caso de que el conjunto incluya una dimensión de tiempo).**\n",
    "\n",
    "R; Por la naturaleza de los datos, En general siguen un mismo patrón en especial al realizar las misma tareas pero varían dependiendo de la información de cada usuario o paciente, en ese aspecto podriamos argumentar  que los datos se pueden considerar como un poco ruidosas, en otras palabras, variaciones aleatorias o impredecibles en los datos que no siguen ningún patrón claro.\n",
    "\n",
    "**¿Cómo se distribuyen los datos en función de diferentes categorías? (análisis bivariado)**\n",
    "\n",
    "R: Por lo general las etiquetas tienen una correlacion, el resto de los datos, tienen su propia distrubicion, por ejemplo el estatus de la pluma solo tiene una distrbucion binaria (0 y 1).\n",
    "\n",
    "**¿Se deberían normalizar las imágenes para visualizarlas mejor?**\n",
    "\n",
    "R: El set de datos no requiere normalizacion de imagenes, ya que usa pricnipalmente series de tiempo\n",
    "\n",
    "**¿Hay desequilibrio en las clases de la variable objetivo?**\n",
    "\n",
    "R: Existe un ligero desbalance en las etiquetas ya que los pacientes tienen datos de mayor cantidad o existe paciente que sufre estres mas que ansiedad y depresion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c516315f9284bc",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a82d3c",
   "metadata": {},
   "source": [
    "Después de realizar el EDA, nos pudimos familiarizar mas con los datos que estaremos trabajando y las tendencias que existen dentro de nuestros datos, de manera general consideramos que los puntos mas importantes a considerar son los siguientes:\n",
    "\n",
    "*   **homework:** Podemos observar que hay un mínimo de 0 tareas y 7 como máximo.\n",
    "*   **pen_status:** El valor medio es 0,57, lo que sugiere que la mayoría de las muestras se encuentran con el valor de 1.\n",
    "*   El valor máximo de **depression, anxiety y stress:** es 25, 15 y 39, respectivamente.\n",
    "\n",
    "*   El valor mas alto siendo 39 de **stress**\n",
    "\n",
    "*   Existen datos atípicos principalmente en las etiquetas de nuestros datos, de los cuales las etiquetas tienen correlación consigo mismas.\n",
    "\n",
    "*   En las series de tiempo, especialmente cuando hablamos de coordenadas X y Y, tiene la misma tendencia cuando se comparan las mismas tareas en diferentes pacientes. Esto tiene sentido ya que están realizando una tarea similar pero no es lo mismo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b677120024f2992",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253ca9749d53893",
   "metadata": {},
   "source": [
    "Faundez-Zanuy, M. (2025). Comprehensive analysis of least significant bit and difference expansion watermarking algorithms for online signature signals. Expert Systems with Applications, 267, 126214. [https://doi.org/10.1016/j.eswa.2024.126214](https://doi.org/10.1016/j.eswa.2024.126214)\n",
    "\n",
    "Likforman-Sulem, L., Esposito, A., Faundez-Zanuy, M., Clemençon, S., & Cordasco, G. (2017). EMOTHAW: A novel database for emotional state recognition from handwriting and drawing. IEEE Transactions on Human-Machine Systems, 47(2), 273–284. [https://doi.org/10.1109/THMS.2016.2635441](https://doi.org/10.1109/THMS.2016.2635441)\n",
    "\n",
    "\n",
    "Nolazco-Flores, J. A., Faundez-Zanuy, M., Velázquez-Flores, O. A., Cordasco, G., & Esposito, A. (2021). Emotional state recognition performance improvement on a handwriting and drawing task. IEEE Access, 9, 28496–28504. [https://doi.org/10.1109/ACCESS.2021.3058443](https://doi.org/10.1109/ACCESS.2021.3058443)\n",
    "\n",
    "San Roman, R., Fernandez, P., Défossez, A., Furon, T., Tran, T., & Elsahar, H. (2024). Proactive detection of voice cloning with localized watermarking. arXiv. [https://arxiv.org/abs/2401.17264](https://arxiv.org/abs/2401.17264)"
   ]
  },
  {
   "cell_type": "code",
   "id": "50d233b63839f0c4",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto-integrador-equipo-11-RpNcPuS5-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
